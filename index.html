<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Bodun Hu's personal website.">
    <!-- <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@soumithchintala"> -->
    <!-- <script defer="defer" data-domain="bodunhu.com" src="Soumith%20Chintala_files/noop.js"></script> -->
    <link rel="canonical" href="https://www.bodunhu.com/">

    <title>Bodun Hu</title>
    <style>
        body {
            line-height: 1.5;
            max-width: 650px;
            margin: 50px auto;
            padding: 20px;
        }

        nav a {
            margin-right: 10px;
        }

        .name-link {
            color: black;
            /* text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.1); */
            text-decoration: none;
            font-size: 1.5em;
            /* Increased font size */
            font-weight: bold;
            /* Added to ensure the text remains bold */
        }

        details>summary {
            list-style: none;
        }

        /* details > summary::-webkit-details-marker {
	  display: none;
      } */
    </style>
</head>

<body>
    <header>
        <nav>
            <a href="https://www.bodunhu.com" class="name-link"><b>Bodun Hu</b></a>
            |&nbsp;&nbsp; <a href="https://www.bodunhu.com/blog">Blog</a>
            <a href="/files/cv.pdf">CV</a>
            <a href="https://x.com/bodunhu">X</a>
            <a href="https://github.com/BDHU">GitHub</a>
            <a href="https://scholar.google.com/citations?user=zR6afi8AAAAJ&hl=en">Publications</a>
        </nav>
    </header>
    <main>
        <p>My name is Bodun Hu (though I usually go by Edward). I'm a PhD student at <a href="https://www.utexas.edu/">UT Austin</a>,
            majoring in Computer Science. I'm fortunately to be advised by <a href="https://www.cs.utexas.edu/~akella/">Aditya Akella</a>
            at <a href="https://utns.cs.utexas.edu/">UTNS</a> lab.</p>

        <p>My research lies at the intersection of machine learning, operating systems, and network. I love building systems for ML.</p>

        <p>I got both a MS and BS in Computer Science from UT Austin. Before starting my PhD, I worked
            with <a href="https://www.cs.utexas.edu/~rossbach/">Christopher Rossbach</a> at
            SCEA lab, focsuing on GPU benchmarking and developing methods to enable OS kernel access to accelerators.</p>

        <p>I have been very fortunate to intern with <a href="https://theojepsen.dk/">Theo Jepsen</a> and
            <a href="https://www.linkedin.com/in/georgiosnikolaidis">Georgios Nikolaidis</a> at Intel.
            I will be joining Meta's <a href="https://aisystemcodesign.github.io/">AI and Systems Co-design team</a> as an intern this summer, where I will help
            build infrastructure to faciliate LLM training.</p>

        <p>Contact: <em>bodunhu at utexas.edu</em><br>
        PGP key: <a href="https://keys.openpgp.org/vks/v1/by-fingerprint/A1B9B452CA88126F31C3D3E276F092F8CD673517">76F092F8CD673517</a></p>

        <!-- <ul>
            <li>Live in New York. Grew up in Hyderabad, India.</li>
            <li>Studied at <a href="https://www.nyu.edu/">NYU</a> and <a href="https://vit.ac.in/">VIT Vellore</a>.
            </li>
            <li>
                <details>
                    <summary>
                        Currently at Meta and NYU, focusing on AI Infrastructure, AI Research and Robotics.
                    </summary>
                </details>
            </li>
            <li>
                <details>
                    <summary>
                        Co-founded <a href="https://pytorch.org/">PyTorch</a>, maintained <a
                            href="http://torch.ch/">Torch-7</a> and actively work on open-source.
                        <span style="color:grey">&nbsp;&nbsp; <i>[expand]</i></span>
                    </summary>

                    <ul>
                        <li> PyTorch is the most impactful project that I've been involved
                            in, and now powers most of the world's AI research and product -- with
                            hundreds of companies, research labs and individuals using and
                            maintaining it. It has <a href="https://pytorch.org/community-stories">significant and
                                tangible real-world impact</a>
                            from self-driving cars (Tesla, Cruise, Uber, etc.) to drug discovery
                            (Astra Zenenca, Genentech, etc.) to cancer research (Bamfield / MARS
                            Company) to NASA and other space research to several consumer products
                            (Instagram, TikTok, Snapchat, Pinterest, etc.), and this amount of
                            real-world usage often intimidates me. There's more than one bug in
                            PyTorch, when it was uncovered, I couldn't sleep thinking about what the
                            downstream effects could be. PyTorch has been impactful far beyond my
                            expectations or ambition.
                        </li>
                        <li>
                            Torch-7 at it’s peak was used by Google Deepmind, Twitter and Meta and singificant AI
                            research was powered by it.
                        </li>
                        <li>
                            Created <a href="https://github.com/soumith/convnet-benchmarks">convnet-benchmarks</a>,
                            a once popular benchmarking suite for deep learning. It was used from
                            2015 to 2017 as a gold standard by NVIDIA, AMD, Intel Nervana and many
                            other hardware manufacturers to optimize their systems
                        </li>
                        <li>
                            I used to maintain <a href="https://eblearn.sourceforge.net/">EBLearn</a>, a C++ based Deep
                            Learning Framework pre-2012, together with Pierre Sermanet and Yann LeCun.
                        </li>
                    </ul>
                </details>
            </li>
            <li>
                <details>
                    <summary>
                        Published well-cited AI research in Generating Images and other AI things.<span
                            style="color:grey">&nbsp;&nbsp; <i>[expand]</i></span>
                    </summary>
                    <ul>
                        <li>
                            Some of my most cited work is on Generative Adversarial networks (GANs), where I co-authored
                            three well-cited papers: <a
                                href="http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-5">LAPGAN</a>
                            (<a href="http://soumith.ch/eyescream/">demo</a>), <a
                                href="https://arxiv.org/abs/1511.06434">DCGAN</a> (<a
                                href="https://github.com/Newmu/dcgan_code">code/demo</a>) and <a
                                href="https://arxiv.org/abs/1701.07875">Wasserstein GAN</a>. I gave up on GANs after
                            failing to make them stable training algorithms.
                        </li>
                        <li>
                            I've worked on <a href="https://arxiv.org/abs/1604.02135">object</a> and <a
                                href="http://openaccess.thecvf.com/content_cvpr_2013/html/Sermanet_Pedestrian_Detection_with_2013_CVPR_paper.html">human</a>
                            detection, generative modeling of {<a
                                href="http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-5">images</a>,
                            videos}, <a href="https://arxiv.org/abs/1609.02993">AI for video games</a>, <a
                                href="https://arxiv.org/abs/1412.7580">ML systems research</a>.
                        </li>
                        <li>A full list of my peer-reviewed or pre-print manuscripts are on my <a
                                href="https://scholar.google.com/citations?user=36ofBJgAAAAJ&amp;hl=en">Google Scholar
                                page</a>.
                        </li>
                    </ul>
                </details>
            </li>
            <li>Working on automating chores at home using robots.</li>

        </ul> -->

        <p> Here’s the list of publications:</p>

        <ul>
            <li><a href="https://arxiv.org/pdf/2505.13444">ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models</a>, ArXiv<br>
                <em>Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, <strong>Bodun Hu</strong>, Juan Diego Rodriguez, Puyuan Peng, Greg Durret</em>
            </li>
            <li><a href="https://arxiv.org/pdf/2505.07833">Patchwork: A Unified Framework for RAG Serving</a>, ArXiv<br>
                <em><strong>Bodun Hu</strong>*, Luis Pabon*, Saurabh Agarwawl, Aditya Akella</em>
            </li>
            <li><a href="https://arxiv.org/pdf/2404.18322">BlockLLM: Multi-tenant Finer-grained Serving for Large Language Models</a>, ArXiv<br>
                <em><strong>Bodun Hu</strong>, Jiamin Li, Le Xu, Myungjin Lee, Akshay Jajoo, Geon-Woo Kim, Hong Xu, Aditya Akella</em>
            </li>
            <li><a href="https://aclanthology.org/2024.emnlp-main.501.pdf">MOSEL: Inference Serving Using Dynamic Modality Selection</a>, EMNLP 2024<br>
                <em><strong>Bodun Hu</strong>, Le Xu, Jeongyoon Moon, Neeraja J. Yadwadkar, Aditya Akella</em>
            </li>
            <li><a href="https://arxiv.org/pdf/2404.03865">FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping</a>, EMNLP 2024<br>
                <em>Ajay Jaiswal, <strong>Bodun Hu</strong>, Lu Yin, Yeonju Ro, Shiwei Liu, Tianlong Chen, Aditya Aeklla</em>
            </li>
            <li><a href="https://dl.acm.org/doi/pdf/10.1145/3575693.3575697">Towards a Machine Learning-Assisted Kernel with LAKE</a>, ASPLOS 2023<br>
                <em>Henrique Fingler, Isha Tarte, Hangchen Yu, Ariel Szekely, <strong>Bodun Hu</strong>, Aditya Akella, Christopher J. Rossbach</em>
            </li>
            <li><a href="https://ieeexplore.ieee.org/document/9238617">Altis: Modernizing GPGPU Benchmarks</a>, ISPASS 2020<br>
                <em><strong>Bodun Hu</strong>, Christopher J. Rossbach</em>
        </ul>

        <p>Teaching:</p>

        <ul>
            <li><a href="https://www.cs.utexas.edu/~akella/CS378/F24/index.html">Fall 2024: CS 378 System For Machine Learning and Big Data</a>
            </li>
            <li><a href="https://www.cs.utexas.edu/~simon/378/">Spring 2020: CS 378 Multicore Operating System Implementation</a>
            </li>
        </ul>

        <p>Service:</p>

        <p>Reviewer: ACL 2025, ACL-SRW 2025</p>

    </main>


</body>

</html>
